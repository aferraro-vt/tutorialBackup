{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Features and Clustering\n",
        "The content of this tutorial was developed by Team 3 as part of an engineering project management class. This is a straightforward tutorial on using the Extracted Features from the previous Tutorial to set up the activations. We tinker with activations in two Clustering Algorithms, and then proceed to visualize the clusters using pca plots."
      ],
      "metadata": {
        "id": "q23fPttzb4-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71QPZgtYcISe",
        "outputId": "db95a10b-291e-4ef9-cd0c-2892d0d188d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up The Activations From The Extracted Features\n",
        "\n",
        "This code imports necessary libraries such as PyTorch, scikit-learn, and matplotlib for data manipulation, neural network modeling, visualization, and clustering tasks. It also loads pre-computed features (referred to as \"checkpoints\") from different layers of various convolutional neural network (CNN) models. These features, along with their corresponding labels, are stored in separate variables (activations1, activations2, activations3, labels1, labels2, labels3). The code sets up the environment for subsequent data analysis, feature manipulation, and clustering operations."
      ],
      "metadata": {
        "id": "0IuMQAZq_04e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "from scipy.signal import resample_poly\n",
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# All of these \"checkpoints\" are features from different layers of different cnn models\n",
        "# Change this how you see fit\n",
        "checkpoint1 = torch.load('activations1.pth')\n",
        "checkpoint2 = torch.load('activations2.pth')\n",
        "checkpoint3 = torch.load('activations3.pth')\n",
        "\n",
        "activations1 = checkpoint1['activations1']\n",
        "labels1 = checkpoint1['labels1']\n",
        "\n",
        "activations2 = checkpoint2['activations2']\n",
        "labels2 = checkpoint2['labels2']\n",
        "\n",
        "activations3 = checkpoint3['activations3']\n",
        "labels3 = checkpoint3['labels3']\n",
        "\n",
        "# You can use the clustering agorithm with features from other neural network.\n",
        "# This tutorial helps you to begin to understand the objective of the cloudd-rf project."
      ],
      "metadata": {
        "id": "s7nT5c2R_z_l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "8031435a-5c03-4d0a-89c3-e190d3ce48de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Tutorial Data Info/activations1.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1c6ab3d9737a>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# All of these \"checkpoints\" are features from different layers of different cnn models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Change this how you see fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mcheckpoint1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Tutorial Data Info/activations1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mcheckpoint2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activations2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcheckpoint3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activations3.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Tutorial Data Info/activations1.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Activations in XGBoost Cluster Algorithm\n",
        "\n",
        "XGBoost (eXtreme Gradient Boosting) is a powerful machine learning algorithm used for supervised learning tasks, particularly for regression and classification problems. It builds a series of decision trees sequentially, where each subsequent tree corrects the errors made by the previous one. XGBoost combines the strengths of gradient boosting with several enhancements, such as regularization, parallel processing, and handling missing values. It optimizes the model's performance by minimizing a specific loss function, often using gradient descent methods. XGBoost is known for its high predictive accuracy, scalability, and efficiency, making it a popular choice in data science competitions and real-world applications."
      ],
      "metadata": {
        "id": "VpL-g_mC3qGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7eVudFdrnto"
      },
      "outputs": [],
      "source": [
        "# Where activations2 is, is wher you can put the activations of another team in.\n",
        "word_map = { 0: '2-ASK', 1: 'BPSK', 2: 'Cnst T', 3: 'P-FMCW', 4: 'N-FMCW'}\n",
        "label = ['2-ASK', 'BPSK', 'Cnst T', 'P-FMCW', 'N-FMCW']\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# This for loop makes it so that axis 1 is the same size across all activations\n",
        "new = torch.zeros_like(activations2)\n",
        "for x in range(activations3.shape[0]):\n",
        "    for y in range(activations3.shape[1]):\n",
        "        new[x,y] = activations3[x,y]\n",
        "activations3 = new\n",
        "\n",
        "\n",
        "# Combine activations and labels from different checkpoints\n",
        "all_activations = np.concatenate([activations3, activations2], axis=0)\n",
        "all_labels = np.concatenate([labels3, labels2], axis=0)\n",
        "\n",
        "# Flatten activations if needed\n",
        "flat_activations = all_activations.reshape(all_activations.shape[0], -1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(flat_activations, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'multi:softmax',  # for multiclass classification\n",
        "    'num_class': len(label),       # number of classes\n",
        "    'eval_metric': 'mlogloss'      # use cross-entropy loss for multiclass\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "num_rounds = 100\n",
        "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_model.predict(dtest)\n",
        "\n",
        "# Convert predictions to integers\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {100*accuracy}\", \"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Activations in Random Forest Cluster Algorithm\n",
        "\n",
        "Random Forest is an ensemble learning technique used for both classification and regression tasks. It builds multiple decision trees during training and combines their predictions to make more accurate and robust predictions. Each decision tree in the Random Forest is trained on a subset of the training data and a random subset of features, which introduces randomness and reduces overfitting. During prediction, each tree in the forest independently predicts the target variable, and the final prediction is determined by aggregating the predictions from all trees (e.g., by taking the majority vote for classification or the average for regression). Random Forest is known for its simplicity, scalability, and ability to handle high-dimensional data and nonlinear relationships, making it a popular choice in machine learning for various applications."
      ],
      "metadata": {
        "id": "xhpyQHRv3usx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Where activations2 is, is where you can put the activations of another team in.\n",
        "word_map = {0: '2-ASK', 1: 'BPSK', 2: 'Cnst T', 3: 'P-FMCW', 4: 'N-FMCW'}\n",
        "label = ['2-ASK', 'BPSK', 'Cnst T', 'P-FMCW', 'N-FMCW']\n",
        "\n",
        "# Flatten activations if needed\n",
        "flat_activations = activations3.reshape(activations3.shape[0], -1)\n",
        "\n",
        "# Combine activations and labels from different checkpoints\n",
        "all_activations = np.concatenate([flat_activations, activations2], axis=0)\n",
        "all_labels = np.concatenate([labels3, labels2], axis=0)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_activations, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {100*accuracy} %\")"
      ],
      "metadata": {
        "id": "B472Yx6S33Za"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}